{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c66704a-e9d0-4593-b2b0-8daec5a98059",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced Time Series Forecasting with Deep Learning and Explainability using an LSTM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f7b04133-5009-4693-9ac8-dbc5db282c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Advanced Time Series Forecasting with LSTM and SHAP\n",
    "# ============================================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "\n",
    "import shap\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "tf.random.set_seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c933ef06-ed7e-459a-a906-03b6e6ca3276",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (6000, 4)\n",
      "   feature_temp  feature_volume  feature_noise    target\n",
      "0      0.248357       -1.114081       2.349628  0.210670\n",
      "1      0.191534       -0.316978      -3.757962 -0.746648\n",
      "2      0.841224       -0.315394      -0.655590  0.690235\n",
      "3      1.527764        0.388911      -0.083320  0.729819\n",
      "4      0.886431        1.029299       0.031817  1.218607\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------\n",
    "# 1. Generate a synthetic multivariate time series dataset\n",
    "# ------------------------------------------------------------\n",
    "def generate_synthetic_multivariate_series(n_timesteps=6000):\n",
    "    \"\"\"\n",
    "    Create a synthetic multivariate time series with trends,\n",
    "    seasonality, and noise.\n",
    "    \n",
    "    Returns:\n",
    "        df: pandas DataFrame with columns:\n",
    "            ['feature_temp', 'feature_volume', 'feature_noise', 'target']\n",
    "    \"\"\"\n",
    "    t = np.arange(n_timesteps)\n",
    "\n",
    "    # Feature 1: Slowly increasing trend + seasonality\n",
    "    temp = 0.01 * t + 2 * np.sin(2 * np.pi * t / 50) + np.random.normal(scale=0.5, size=n_timesteps)\n",
    "\n",
    "    # Feature 2: Seasonality with different frequency\n",
    "    volume = 5 * np.sin(2 * np.pi * t / 100) + np.random.normal(scale=1.0, size=n_timesteps)\n",
    "\n",
    "    # Feature 3: Mostly noise\n",
    "    noise_feature = np.random.normal(scale=2.0, size=n_timesteps)\n",
    "\n",
    "    # Target depends on past values of features\n",
    "    target = (\n",
    "        0.6 * temp +\n",
    "        0.3 * volume +\n",
    "        0.1 * noise_feature +\n",
    "        np.random.normal(scale=0.5, size=n_timesteps)\n",
    "    )\n",
    "\n",
    "    data = {\n",
    "        \"feature_temp\": temp,\n",
    "        \"feature_volume\": volume,\n",
    "        \"feature_noise\": noise_feature,\n",
    "        \"target\": target,\n",
    "    }\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "df = generate_synthetic_multivariate_series()\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7192504d-93fc-4181-a9d7-24cb8006a7e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (5970, 30, 3)\n",
      "y shape: (5970,)\n",
      "Train: (4179, 30, 3) Val: (895, 30, 3) Test: (896, 30, 3)\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------\n",
    "# 2. Preprocessing: scaling, windowing, train/val/test split\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "# Features and target\n",
    "FEATURE_COLUMNS = [\"feature_temp\", \"feature_volume\", \"feature_noise\"]\n",
    "TARGET_COLUMN = \"target\"\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(df[FEATURE_COLUMNS + [TARGET_COLUMN]])\n",
    "scaled_df = pd.DataFrame(\n",
    "    scaled_features,\n",
    "    columns=FEATURE_COLUMNS + [TARGET_COLUMN]\n",
    ")\n",
    "\n",
    "def create_windowed_dataset(data, feature_cols, target_col, window_size=30, horizon=1):\n",
    "    \"\"\"\n",
    "    Convert a time series into windowed samples:\n",
    "    X: [samples, timesteps, features]\n",
    "    y: [samples,]\n",
    "    \"\"\"\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - window_size - horizon + 1):\n",
    "        window = data[feature_cols].iloc[i : i + window_size].values\n",
    "        target = data[target_col].iloc[i + window_size + horizon - 1]\n",
    "        X.append(window)\n",
    "        y.append(target)\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "WINDOW_SIZE = 30\n",
    "HORIZON = 1\n",
    "\n",
    "X, y = create_windowed_dataset(\n",
    "    scaled_df,\n",
    "    feature_cols=FEATURE_COLUMNS,\n",
    "    target_col=TARGET_COLUMN,\n",
    "    window_size=WINDOW_SIZE,\n",
    "    horizon=HORIZON,\n",
    ")\n",
    "\n",
    "print(\"X shape:\", X.shape)  # (samples, timesteps, features)\n",
    "print(\"y shape:\", y.shape)\n",
    "\n",
    "# Train/validation/test split\n",
    "# First split into train + temp, then temp -> val + test\n",
    "X_train_full, X_temp, y_train_full, y_temp = train_test_split(\n",
    "    X, y, test_size=0.3, shuffle=False\n",
    ")\n",
    "\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.5, shuffle=False\n",
    ")\n",
    "\n",
    "print(\"Train:\", X_train_full.shape, \"Val:\", X_val.shape, \"Test:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aa926e43-f1d8-4e85-ae52-50e9f293f098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model with units=32, lr=0.001, dropout=0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rohit\\tfenv\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation RMSE: 0.1234\n",
      "\n",
      "Training model with units=32, lr=0.001, dropout=0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rohit\\tfenv\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation RMSE: 0.1905\n",
      "\n",
      "Training model with units=32, lr=0.0005, dropout=0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rohit\\tfenv\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation RMSE: 0.1630\n",
      "\n",
      "Training model with units=32, lr=0.0005, dropout=0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rohit\\tfenv\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation RMSE: 0.1532\n",
      "\n",
      "Training model with units=64, lr=0.001, dropout=0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rohit\\tfenv\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation RMSE: 0.0775\n",
      "\n",
      "Training model with units=64, lr=0.001, dropout=0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rohit\\tfenv\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation RMSE: 0.0764\n",
      "\n",
      "Training model with units=64, lr=0.0005, dropout=0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rohit\\tfenv\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation RMSE: 0.1224\n",
      "\n",
      "Training model with units=64, lr=0.0005, dropout=0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rohit\\tfenv\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation RMSE: 0.1692\n",
      "\n",
      "Best config: {'lstm_units': 64, 'learning_rate': 0.001, 'dropout_rate': 0.3}\n",
      "Best validation RMSE: 0.07641575629031638\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------\n",
    "# 3. Build LSTM model + simple hyperparameter search\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "def build_lstm_model(\n",
    "    input_shape,\n",
    "    lstm_units=64,\n",
    "    dense_units=32,\n",
    "    dropout_rate=0.2,\n",
    "    learning_rate=1e-3\n",
    "):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(lstm_units, input_shape=input_shape, return_sequences=False))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(dense_units, activation=\"relu\"))\n",
    "    model.add(Dense(1))  # Regression output\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    model.compile(\n",
    "        loss=\"mse\",\n",
    "        optimizer=optimizer,\n",
    "        metrics=[\"mae\"]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# Hyperparameter grids (keep small for demo; can expand for more exhaustive search)\n",
    "lstm_units_list = [32, 64]\n",
    "learning_rates = [1e-3, 5e-4]\n",
    "dropout_rates = [0.2, 0.3]\n",
    "\n",
    "best_val_rmse = float(\"inf\")\n",
    "best_config = None\n",
    "best_model = None\n",
    "\n",
    "EPOCHS = 15\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "input_shape = (X_train_full.shape[1], X_train_full.shape[2])\n",
    "\n",
    "for lstm_units in lstm_units_list:\n",
    "    for lr in learning_rates:\n",
    "        for dr in dropout_rates:\n",
    "            print(f\"\\nTraining model with units={lstm_units}, lr={lr}, dropout={dr}\")\n",
    "            model = build_lstm_model(\n",
    "                input_shape=input_shape,\n",
    "                lstm_units=lstm_units,\n",
    "                dense_units=32,\n",
    "                dropout_rate=dr,\n",
    "                learning_rate=lr\n",
    "            )\n",
    "\n",
    "            history = model.fit(\n",
    "                X_train_full, y_train_full,\n",
    "                validation_data=(X_val, y_val),\n",
    "                epochs=EPOCHS,\n",
    "                batch_size=BATCH_SIZE,\n",
    "                verbose=0\n",
    "            )\n",
    "\n",
    "            # Compute validation RMSE\n",
    "            val_preds = model.predict(X_val, verbose=0)\n",
    "            val_rmse = np.sqrt(mean_squared_error(y_val, val_preds))\n",
    "\n",
    "            print(f\"Validation RMSE: {val_rmse:.4f}\")\n",
    "\n",
    "            if val_rmse < best_val_rmse:\n",
    "                best_val_rmse = val_rmse\n",
    "                best_config = {\n",
    "                    \"lstm_units\": lstm_units,\n",
    "                    \"learning_rate\": lr,\n",
    "                    \"dropout_rate\": dr,\n",
    "                }\n",
    "                best_model = model\n",
    "\n",
    "print(\"\\nBest config:\", best_config)\n",
    "print(\"Best validation RMSE:\", best_val_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d4b05cc6-2dc6-485c-b173-17a349eead9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test RMSE: 0.11236933744378826\n",
      "Test MAE: 0.09219349818115033\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------\n",
    "# 4. Final evaluation on test set\n",
    "# ------------------------------------------------------------\n",
    "test_preds = best_model.predict(X_test, verbose=0)\n",
    "test_rmse = np.sqrt(mean_squared_error(y_test, test_preds))\n",
    "test_mae = mean_absolute_error(y_test, test_preds)\n",
    "\n",
    "print(\"\\nTest RMSE:\", test_rmse)\n",
    "print(\"Test MAE:\", test_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8d8f5df7-294f-4857-b16e-1a2ac58ecfe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 200 background data samples could cause slower run times. Consider using shap.sample(data, K) or shap.kmeans(data, K) to summarize the background as K samples.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2953e72417604472bf1adf7eeb9d100b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHAP values computed using KernelExplainer.\n",
      "\n",
      "Mean |SHAP| Feature Importance:\n",
      "  feature_temp: 0.0957\n",
      "  feature_volume: 0.0000\n",
      "  feature_noise: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rohit\\AppData\\Local\\Temp\\ipykernel_14468\\751322682.py:43: FutureWarning: The NumPy global RNG was seeded by calling `np.random.seed`. In a future version this function will no longer use the global RNG. Pass `rng` explicitly to opt-in to the new behaviour and silence this warning.\n",
      "  shap.summary_plot(shap_values, test_samples)\n",
      "C:\\Users\\rohit\\tfenv\\lib\\site-packages\\shap\\plots\\_beeswarm.py:723: FutureWarning: The NumPy global RNG was seeded by calling `np.random.seed`. In a future version this function will no longer use the global RNG. Pass `rng` explicitly to opt-in to the new behaviour and silence this warning.\n",
      "  summary_legacy(\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1150x660 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ------------------------------------------------------------\n",
    "# 5. SHAP Explainability (KernelExplainer - fully compatible)\n",
    "# ------------------------------------------------------------\n",
    "import shap\n",
    "\n",
    "# KernelExplainer requires samples in 2D, so reshape:\n",
    "X_train_kernel = X_train_full.reshape((X_train_full.shape[0], -1))\n",
    "X_test_kernel = X_test.reshape((X_test.shape[0], -1))\n",
    "\n",
    "# Define a prediction function that accepts 2D input\n",
    "def predict_kernel(x):\n",
    "    x_reshaped = x.reshape((x.shape[0], WINDOW_SIZE, len(FEATURE_COLUMNS)))\n",
    "    return best_model.predict(x_reshaped, verbose=0)\n",
    "\n",
    "# Use a small background dataset to keep SHAP fast\n",
    "background = X_train_kernel[:200]\n",
    "\n",
    "explainer = shap.KernelExplainer(predict_kernel, background)\n",
    "\n",
    "# Compute SHAP values for 50 test samples\n",
    "test_samples = X_test_kernel[:50]\n",
    "shap_values = explainer.shap_values(test_samples)\n",
    "\n",
    "print(\"SHAP values computed using KernelExplainer.\")\n",
    "\n",
    "# -------- Feature Importance (averaged across time steps) ------\n",
    "shap_array = np.array(shap_values)\n",
    "# shap_array shape â†’ (1, samples, features_flat)\n",
    "\n",
    "# Reshape back: (samples, timesteps, features)\n",
    "shap_array = shap_array.reshape(\n",
    "    50, WINDOW_SIZE, len(FEATURE_COLUMNS)\n",
    ")\n",
    "\n",
    "# Mean importance across samples + time\n",
    "mean_abs_shap = np.mean(np.abs(shap_array), axis=(0, 1))\n",
    "\n",
    "print(\"\\nMean |SHAP| Feature Importance:\")\n",
    "for feat, val in zip(FEATURE_COLUMNS, mean_abs_shap):\n",
    "    print(f\"  {feat}: {val:.4f}\")\n",
    "\n",
    "# ----- Optional Summary Plot (stable for KernelExplainer) ------\n",
    "shap.summary_plot(shap_values, test_samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "522a20c9-be53-4181-8ab3-44211c09e2cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicted next-step (original scale) target value: 34.04927729845361\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------\n",
    "# 6. Utility: simple prediction demo for the latest window\n",
    "# ------------------------------------------------------------\n",
    "def predict_next_step(model, scaled_df, feature_cols, window_size=30):\n",
    "    last_window = scaled_df[feature_cols].iloc[-window_size:].values\n",
    "    last_window = np.expand_dims(last_window, axis=0)\n",
    "    pred_scaled = model.predict(last_window, verbose=0)[0][0]\n",
    "    # Inverse transform only target: build dummy row\n",
    "    dummy = np.zeros((1, len(feature_cols) + 1))\n",
    "    dummy[0, -1] = pred_scaled\n",
    "    inv = scaler.inverse_transform(dummy)\n",
    "    return inv[0, -1]\n",
    "\n",
    "next_value = predict_next_step(best_model, scaled_df, FEATURE_COLUMNS, WINDOW_SIZE)\n",
    "print(\"\\nPredicted next-step (original scale) target value:\", next_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87d66db-ce5c-4bc3-af86-fc4f720bc8fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
