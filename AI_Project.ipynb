{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c66704a-e9d0-4593-b2b0-8daec5a98059",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced Time Series Forecasting with Deep Learning and Explainability using an LSTM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7b04133-5009-4693-9ac8-dbc5db282c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Advanced Time Series Forecasting with LSTM and SHAP\n",
    "# ============================================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "\n",
    "import shap\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "tf.random.set_seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c933ef06-ed7e-459a-a906-03b6e6ca3276",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (6000, 4)\n",
      "   feature_temp  feature_volume  feature_noise    target\n",
      "0      0.248357       -1.114081       2.349628  0.210670\n",
      "1      0.191534       -0.316978      -3.757962 -0.746648\n",
      "2      0.841224       -0.315394      -0.655590  0.690235\n",
      "3      1.527764        0.388911      -0.083320  0.729819\n",
      "4      0.886431        1.029299       0.031817  1.218607\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------\n",
    "# 1. Generate a synthetic multivariate time series dataset\n",
    "# ------------------------------------------------------------\n",
    "def generate_synthetic_multivariate_series(n_timesteps=6000):\n",
    "    \"\"\"\n",
    "    Create a synthetic multivariate time series with trends,\n",
    "    seasonality, and noise.\n",
    "    \n",
    "    Returns:\n",
    "        df: pandas DataFrame with columns:\n",
    "            ['feature_temp', 'feature_volume', 'feature_noise', 'target']\n",
    "    \"\"\"\n",
    "    t = np.arange(n_timesteps)\n",
    "\n",
    "    # Feature 1: Slowly increasing trend + seasonality\n",
    "    temp = 0.01 * t + 2 * np.sin(2 * np.pi * t / 50) + np.random.normal(scale=0.5, size=n_timesteps)\n",
    "\n",
    "    # Feature 2: Seasonality with different frequency\n",
    "    volume = 5 * np.sin(2 * np.pi * t / 100) + np.random.normal(scale=1.0, size=n_timesteps)\n",
    "\n",
    "    # Feature 3: Mostly noise\n",
    "    noise_feature = np.random.normal(scale=2.0, size=n_timesteps)\n",
    "\n",
    "    # Target depends on past values of features\n",
    "    target = (\n",
    "        0.6 * temp +\n",
    "        0.3 * volume +\n",
    "        0.1 * noise_feature +\n",
    "        np.random.normal(scale=0.5, size=n_timesteps)\n",
    "    )\n",
    "\n",
    "    data = {\n",
    "        \"feature_temp\": temp,\n",
    "        \"feature_volume\": volume,\n",
    "        \"feature_noise\": noise_feature,\n",
    "        \"target\": target,\n",
    "    }\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "df = generate_synthetic_multivariate_series()\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7192504d-93fc-4181-a9d7-24cb8006a7e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (5970, 30, 3)\n",
      "y shape: (5970,)\n",
      "Train: (4179, 30, 3) Val: (895, 30, 3) Test: (896, 30, 3)\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------\n",
    "# 2. Preprocessing: scaling, windowing, train/val/test split\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "# Features and target\n",
    "FEATURE_COLUMNS = [\"feature_temp\", \"feature_volume\", \"feature_noise\"]\n",
    "TARGET_COLUMN = \"target\"\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(df[FEATURE_COLUMNS + [TARGET_COLUMN]])\n",
    "scaled_df = pd.DataFrame(\n",
    "    scaled_features,\n",
    "    columns=FEATURE_COLUMNS + [TARGET_COLUMN]\n",
    ")\n",
    "\n",
    "def create_windowed_dataset(data, feature_cols, target_col, window_size=30, horizon=1):\n",
    "    \"\"\"\n",
    "    Convert a time series into windowed samples:\n",
    "    X: [samples, timesteps, features]\n",
    "    y: [samples,]\n",
    "    \"\"\"\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - window_size - horizon + 1):\n",
    "        window = data[feature_cols].iloc[i : i + window_size].values\n",
    "        target = data[target_col].iloc[i + window_size + horizon - 1]\n",
    "        X.append(window)\n",
    "        y.append(target)\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "WINDOW_SIZE = 30\n",
    "HORIZON = 1\n",
    "\n",
    "X, y = create_windowed_dataset(\n",
    "    scaled_df,\n",
    "    feature_cols=FEATURE_COLUMNS,\n",
    "    target_col=TARGET_COLUMN,\n",
    "    window_size=WINDOW_SIZE,\n",
    "    horizon=HORIZON,\n",
    ")\n",
    "\n",
    "print(\"X shape:\", X.shape)  # (samples, timesteps, features)\n",
    "print(\"y shape:\", y.shape)\n",
    "\n",
    "# Train/validation/test split\n",
    "# First split into train + temp, then temp -> val + test\n",
    "X_train_full, X_temp, y_train_full, y_temp = train_test_split(\n",
    "    X, y, test_size=0.3, shuffle=False\n",
    ")\n",
    "\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.5, shuffle=False\n",
    ")\n",
    "\n",
    "print(\"Train:\", X_train_full.shape, \"Val:\", X_val.shape, \"Test:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa926e43-f1d8-4e85-ae52-50e9f293f098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model with units=32, lr=0.001, dropout=0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rohit\\tfenv\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation RMSE: 0.1187\n",
      "\n",
      "Training model with units=32, lr=0.001, dropout=0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rohit\\tfenv\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation RMSE: 0.1637\n",
      "\n",
      "Training model with units=32, lr=0.0005, dropout=0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rohit\\tfenv\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation RMSE: 0.1390\n",
      "\n",
      "Training model with units=32, lr=0.0005, dropout=0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rohit\\tfenv\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation RMSE: 0.1841\n",
      "\n",
      "Training model with units=64, lr=0.001, dropout=0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rohit\\tfenv\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation RMSE: 0.0794\n",
      "\n",
      "Training model with units=64, lr=0.001, dropout=0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rohit\\tfenv\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation RMSE: 0.0769\n",
      "\n",
      "Training model with units=64, lr=0.0005, dropout=0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rohit\\tfenv\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation RMSE: 0.0898\n",
      "\n",
      "Training model with units=64, lr=0.0005, dropout=0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rohit\\tfenv\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation RMSE: 0.1262\n",
      "\n",
      "Best config: {'lstm_units': 64, 'learning_rate': 0.001, 'dropout_rate': 0.3}\n",
      "Best validation RMSE: 0.07688567649644609\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------\n",
    "# 3. Build LSTM model + simple hyperparameter search\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "def build_lstm_model(\n",
    "    input_shape,\n",
    "    lstm_units=64,\n",
    "    dense_units=32,\n",
    "    dropout_rate=0.2,\n",
    "    learning_rate=1e-3\n",
    "):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(lstm_units, input_shape=input_shape, return_sequences=False))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(dense_units, activation=\"relu\"))\n",
    "    model.add(Dense(1))  # Regression output\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    model.compile(\n",
    "        loss=\"mse\",\n",
    "        optimizer=optimizer,\n",
    "        metrics=[\"mae\"]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# Hyperparameter grids (keep small for demo; can expand for more exhaustive search)\n",
    "lstm_units_list = [32, 64]\n",
    "learning_rates = [1e-3, 5e-4]\n",
    "dropout_rates = [0.2, 0.3]\n",
    "\n",
    "best_val_rmse = float(\"inf\")\n",
    "best_config = None\n",
    "best_model = None\n",
    "\n",
    "EPOCHS = 15\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "input_shape = (X_train_full.shape[1], X_train_full.shape[2])\n",
    "\n",
    "for lstm_units in lstm_units_list:\n",
    "    for lr in learning_rates:\n",
    "        for dr in dropout_rates:\n",
    "            print(f\"\\nTraining model with units={lstm_units}, lr={lr}, dropout={dr}\")\n",
    "            model = build_lstm_model(\n",
    "                input_shape=input_shape,\n",
    "                lstm_units=lstm_units,\n",
    "                dense_units=32,\n",
    "                dropout_rate=dr,\n",
    "                learning_rate=lr\n",
    "            )\n",
    "\n",
    "            history = model.fit(\n",
    "                X_train_full, y_train_full,\n",
    "                validation_data=(X_val, y_val),\n",
    "                epochs=EPOCHS,\n",
    "                batch_size=BATCH_SIZE,\n",
    "                verbose=0\n",
    "            )\n",
    "\n",
    "            # Compute validation RMSE\n",
    "            val_preds = model.predict(X_val, verbose=0)\n",
    "            val_rmse = np.sqrt(mean_squared_error(y_val, val_preds))\n",
    "\n",
    "            print(f\"Validation RMSE: {val_rmse:.4f}\")\n",
    "\n",
    "            if val_rmse < best_val_rmse:\n",
    "                best_val_rmse = val_rmse\n",
    "                best_config = {\n",
    "                    \"lstm_units\": lstm_units,\n",
    "                    \"learning_rate\": lr,\n",
    "                    \"dropout_rate\": dr,\n",
    "                }\n",
    "                best_model = model\n",
    "\n",
    "print(\"\\nBest config:\", best_config)\n",
    "print(\"Best validation RMSE:\", best_val_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4b05cc6-2dc6-485c-b173-17a349eead9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test RMSE: 0.13750529133559478\n",
      "Test MAE: 0.11509166777852602\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------\n",
    "# 4. Final evaluation on test set\n",
    "# ------------------------------------------------------------\n",
    "test_preds = best_model.predict(X_test, verbose=0)\n",
    "test_rmse = np.sqrt(mean_squared_error(y_test, test_preds))\n",
    "test_mae = mean_absolute_error(y_test, test_preds)\n",
    "\n",
    "print(\"\\nTest RMSE:\", test_rmse)\n",
    "print(\"Test MAE:\", test_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d8f5df7-294f-4857-b16e-1a2ac58ecfe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 200 background data samples could cause slower run times. Consider using shap.sample(data, K) or shap.kmeans(data, K) to summarize the background as K samples.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "243857ef8cd94e3899af232911cfeb00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHAP values computed using KernelExplainer.\n",
      "\n",
      "Mean |SHAP| Feature Importance:\n",
      "  feature_temp: 0.0909\n",
      "  feature_volume: 0.0000\n",
      "  feature_noise: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rohit\\AppData\\Local\\Temp\\ipykernel_14468\\751322682.py:43: FutureWarning: The NumPy global RNG was seeded by calling `np.random.seed`. In a future version this function will no longer use the global RNG. Pass `rng` explicitly to opt-in to the new behaviour and silence this warning.\n",
      "  shap.summary_plot(shap_values, test_samples)\n",
      "C:\\Users\\rohit\\tfenv\\lib\\site-packages\\shap\\plots\\_beeswarm.py:723: FutureWarning: The NumPy global RNG was seeded by calling `np.random.seed`. In a future version this function will no longer use the global RNG. Pass `rng` explicitly to opt-in to the new behaviour and silence this warning.\n",
      "  summary_legacy(\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1150x660 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ------------------------------------------------------------\n",
    "# 5. SHAP Explainability (KernelExplainer - fully compatible)\n",
    "# ------------------------------------------------------------\n",
    "import shap\n",
    "\n",
    "# KernelExplainer requires samples in 2D, so reshape:\n",
    "X_train_kernel = X_train_full.reshape((X_train_full.shape[0], -1))\n",
    "X_test_kernel = X_test.reshape((X_test.shape[0], -1))\n",
    "\n",
    "# Define a prediction function that accepts 2D input\n",
    "def predict_kernel(x):\n",
    "    x_reshaped = x.reshape((x.shape[0], WINDOW_SIZE, len(FEATURE_COLUMNS)))\n",
    "    return best_model.predict(x_reshaped, verbose=0)\n",
    "\n",
    "# Use a small background dataset to keep SHAP fast\n",
    "background = X_train_kernel[:200]\n",
    "\n",
    "explainer = shap.KernelExplainer(predict_kernel, background)\n",
    "\n",
    "# Compute SHAP values for 50 test samples\n",
    "test_samples = X_test_kernel[:50]\n",
    "shap_values = explainer.shap_values(test_samples)\n",
    "\n",
    "print(\"SHAP values computed using KernelExplainer.\")\n",
    "\n",
    "# -------- Feature Importance (averaged across time steps) ------\n",
    "shap_array = np.array(shap_values)\n",
    "# shap_array shape â†’ (1, samples, features_flat)\n",
    "\n",
    "# Reshape back: (samples, timesteps, features)\n",
    "shap_array = shap_array.reshape(\n",
    "    50, WINDOW_SIZE, len(FEATURE_COLUMNS)\n",
    ")\n",
    "\n",
    "# Mean importance across samples + time\n",
    "mean_abs_shap = np.mean(np.abs(shap_array), axis=(0, 1))\n",
    "\n",
    "print(\"\\nMean |SHAP| Feature Importance:\")\n",
    "for feat, val in zip(FEATURE_COLUMNS, mean_abs_shap):\n",
    "    print(f\"  {feat}: {val:.4f}\")\n",
    "\n",
    "# ----- Optional Summary Plot (stable for KernelExplainer) ------\n",
    "shap.summary_plot(shap_values, test_samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "522a20c9-be53-4181-8ab3-44211c09e2cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicted next-step (original scale) target value: 33.425188610611585\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------\n",
    "# 6. Utility: simple prediction demo for the latest window\n",
    "# ------------------------------------------------------------\n",
    "def predict_next_step(model, scaled_df, feature_cols, window_size=30):\n",
    "    last_window = scaled_df[feature_cols].iloc[-window_size:].values\n",
    "    last_window = np.expand_dims(last_window, axis=0)\n",
    "    pred_scaled = model.predict(last_window, verbose=0)[0][0]\n",
    "    # Inverse transform only target: build dummy row\n",
    "    dummy = np.zeros((1, len(feature_cols) + 1))\n",
    "    dummy[0, -1] = pred_scaled\n",
    "    inv = scaler.inverse_transform(dummy)\n",
    "    return inv[0, -1]\n",
    "\n",
    "next_value = predict_next_step(best_model, scaled_df, FEATURE_COLUMNS, WINDOW_SIZE)\n",
    "print(\"\\nPredicted next-step (original scale) target value:\", next_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87d66db-ce5c-4bc3-af86-fc4f720bc8fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
